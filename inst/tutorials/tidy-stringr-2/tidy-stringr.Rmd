---
title: "StringR: Working with Textual Data in R"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
editor_options: 
  chunk_output_type: console
learnr_to_md_options:
  keep_output: false
---

```{r setup, include=FALSE, remove_for_md=TRUE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.path = "img/")
library(learnr)
gradethis::gradethis_setup()
```
<style>
.match {color: red}
li pre {border: 0px; padding: 0; margin:0}
.Info {
    background-color: rgb(204, 229, 255);
    border: 1px solid rgb(184, 218, 255);
    color: rgb(0, 64, 133);
    padding: 1em;
    margin: 1em;
}
.Info::before {
  font-weight: bold;
  content: "ðŸ›ˆ Information";
}
</style>


## Introduction

The goal of this tutorial is to get you acquainted with basic text handling in R. 
A large part of this uses the `stringr` included in the [Tidyverse](https://www.tidyverse.org/). 
For a more exhaustive discussion of regular expressions and the stringr package, see
chapter 9 of [Computational Analysis of Communication](https://cssbook.net/content/chapter09.html), chapter 14 of [R for Data Science](http://r4ds.had.co.nz/), and the [stringr cheat sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/strings.pdf)

Note that in computer jargon, the word 'string' is often used to refer to text or textual data.
This name originates from seeing a text as a 'string' (sequence) of characters.
Interestingly, even though R uses the term `character` for textual values,
the tidyverse package for handling these values is called `stringr`.
In any case, the words `text`, `string`, and `character data` can be seen as synonyms for this tutorial.

## String basics

The package `stringr` has a number of functions for dealing with strings. 
Conveniently, almost all start with `str_`, so in RStudio you can type `str_` and then press tab to get a list of available functions.

### Stringr functions

For all `str_` functions the first argument is the text we are working with, that is, the within which we want to search, replace, or extract something from. 
For example, `str_length` gives the length of the string, `str_to_upper` converts a string to upper case, and `str_detect` tells you whether a string contains a substring (in this case, `johnny` contains `nn`):

```{r str_length, exercise=TRUE}
library(tidyverse)
text = "String is just a fancy name for text"
str_length(text)
str_to_upper(text)
str_detect(text, "fancy")
```

### Combining Strings

To combine two strings, you can use `str_c` (which is equivalent to built-in `paste0`):

```{r str_c, exercise=TRUE}
library(tidyverse)
str_c("john", "mary")
str_c("john", "mary", sep = " & ")
```

It can also work of longer vectors, for example to put a prefix in front of all words in a vector (or column) of texts:

```{r str_c2, exercise=TRUE}
library(tidyverse)
names = c("john", "mary")
str_c("Hello, ", names)
```

### Subsetting Strings

To take a fixed subset of a string, you can use str_sub. This can be useful, for example, to strip the time part off dates:

```{r strsub, exercise=TRUE}
library(tidyverse)
dates <- c("2019-04-01 12:00", "2012-07-29 01:12")
str_sub(dates, start = 1, end = 10)
```

### Exercise: subsetting

Below you have a tibble (data frame) with a date variable. Can you create a new column 'year' that contains only the year part?

```{r exsub, exercise=TRUE, eval=FALSE}
library(tidyverse)
d <- tibble(id=1:2, date=c("2019-04-01 12:00", "2012-07-29 01:12"))
d <- ____
head(d)
```
```{r exsub-solution}
library(tidyverse)
d <- tibble(id=1:2, date=c("2019-04-01 12:00", "2012-07-29 01:12"))
d <- mutate(d, year=str_sub(date, start=1, end=4))
head(d)
```
```{r exsub-code-check}
grade_code()
```


## Using string functions within data frames

The `stringr` functions discussed above directly work on textual **values** rather than data frames (or tibbles). 
Normally, these values would be contained within columns in our data frame. 

For example, we could have a data frame of survey respondents, where we asked people about their favourite animal:

```{r responses}
library(tidyverse)
responses <- tibble(resp_id=c(1:5), name=c("Harry", "Shrek", "Homer", "Winnie", "Lurch"), 
                    answer=c("Owls, of course", "DONKEYS", NA, "owl", ""))
```
```{r exercise=TRUE, showresponses, exercise.setup='responses'}
responses
```

### Changing texts with mutate and stringr

Suppose we would want to select only respondents who have an owl as a favourite animal. 

Since respondents are very careless with using capital letters, 
it makes sense to first convert all responses to lower case.
Since `str_to_lower` works directly on the textual values, 
we can use it within a `mutate` call to change a text within a column:

```{r mutate, exercise=TRUE,  exercise.setup='responses'}
mutate(responses, answer=str_to_lower(answer))
```

### Filtering texts 

Now, we can use `str_detect` within a `filter` function to select only rows containing a specific word.

**Exercise**: Can you complete the code below to convert the responses to lower case, and then select only the respondents that love owls?

```{r filter, exercise=TRUE,  exercise.setup='responses', eval=F}
responses <- mutate(responses, answer=___)
owl_lovers <- filter(responses, ___)
owl_lovers
```
```{r filter-solution}
responses <- mutate(responses, answer=str_to_lower(answer))
owl_lovers <- filter(responses, str_detect(answer, 'owl'))
owl_lovers
```
```{r filter-code-check}
grade_code()
```

### NAs and empty texts

As you can see, two respondents didn't really give an answer.
Homer skipped the question, leading to a missing value (NA).
Lurch, however, entered an empty (zero-length) answer, which is different from a missing value.
One way to deal with this is to use `str_length` within filter to keep only answers with a minimal length,
which can also be useful to remove other answers that are too short (or too long) to be used:

```{r length, exercise=T, exercise.setup='responses'}
filter(responses, str_length(answer) > 1)
```

Note: that automatically also removes the missing values, as `str_length(NA)` results in a missing value,
which causes the row to be removed by the `filter` function.


## Searching for patterns: Regular expressions

The examples above showed how to find a specific word within a string.
In many cases, however, we want to find, replace, or extract certain patterns in a string
(for example, zip codes, dates, email addresses, or html tags).

For this purpose, R (like most other languages) use *regular expressions*, a very powerful way to define
patterns for searching in text. Although a full overview of regular expressions is beyond the scope of this handout 
(there's full books written on the subject!), this tutorial will show you a number of useful patterns.

These patterns can be used in many other languages such as Python, but also in word or excel within the search and replace function!
So, learning regular expressions will be quite useful even if you end up using a different tool than R. 

### Searching for a specific text

```{r strviewhide, echo=FALSE}
# Hide strview output for handout - for interactive this is overwritten in next chunk
str_view <- function(txt, pattern) {
  invisible(stringr::str_view(txt, pattern))
}
```

```{r strview, remove_for_md=TRUE}
# We redefine str_view so it functions well in the interactive tutorial
library(tidyverse)
str_view <- function(txt, pattern) {
  p = str_replace_all(pattern, "\\\\", "&bsol;&bsol;")
  cat(str_c('<h4>Result for <code>', p, '</code></h4>' ))
  cat(stringr::str_view(txt, pattern, html=T)$x$html)
  cat("\n\n")
}
```

To showcase patterns,  we will use the `str_view` command.
This commands highlights the found text within a longer text, 
which is very useful for writing (and debugging!) patterns

As we saw above, we can easily search for a specific word in a text by just searching for that word,
for example the word 'owl':

```{r strview0, exercise=TRUE, results='asis', exercise.setup='strview'}
txt = c("Owls, of course")
str_view(txt, "Owl") 
```

(Note: If you run this on your own computer, you might have to install the htmlwidgets package for this to work)

### Case insensitive matching

Sometimes, it can be useful to match a word regardless of whether it is lower or upper case. 
This can be achieved by defining the pattern more explicitly using the `regex` function,
which allows you to specify options including `ignore_case`:

```{r regex, exercise=TRUE, results='asis', exercise.setup='strview'}
txt = c("Owls, of course", "I have an owl")
str_view(txt, regex("owl", ignore_case = TRUE)) 
```

### Matching whole words

As you can see in the example above, the pattern 'owl' did not really match a word, 
but also the start of the word 'owls'. In fact, all patterns match one or more characters, 
in this case the letters o-w-l, without regard for word boundaries. 
So, it would also match a text like "Guinea fowl" -- a beautiful bird, but not an owl!

To find words, we have to specify a **word boundary** at the start (and maybe the end) of our pattern. 
A word boundary is indicated by the special symbol `\\b`, so two backslashes followed by a b.
So, to match only the word 'owl', the patter would be `\\bowl\\b` 
(so, a `\\b` followed by the word to find, followed by another `\\b`):

```{r boundary, exercise=TRUE, results='asis', exercise.setup='strview'}
txt = c("Owls, of course", "I have an owl", "Guinea fowl are beautiful birds")
str_view(txt, regex("\\bowl\\b", ignore_case = TRUE)) 
```
```{r boundary-solution}
txt = c("Owls, of course", "I have an owl", "Guinea fowl are beautiful birds")
str_view(txt, regex("\\bowl", ignore_case = TRUE)) 
```
```{r boundary-hint}
# If you only have a `\\b` at the start of a pattern, it would match all words starting with that pattern
```
```{r boundary-code-check}
grade_code()
```

**Exercise:** Can you change the code above to match any word starting with owl? 
(so it should match 'owl' and 'owls', but not 'fowl')


### Finding numbers

Another common use case is to look for numbers within a text.
For example, respondents might give their age or mention a frequency in an open text.
It can also be useful to search for e.g. years or phone numbers. 

There's a special symbol `\\d` that matches a number (a **d**igit).
So, suppose we have list of song titles:

```{r, songs, echo=F}
songs = tribble(~author, ~title,
                "Nena", "99 Luftballons",
                "Billy Eilish", "Birds of a feather",
                "Pretenders", "2000 miles",
                "Pink Floyd", "Summer of '69")
```

```{r, echo=F}
library(tidyverse)
songs = tribble(~author, ~title,
                "Nena", "99 Luftballons",
                "Billy Eilish", "Birds of a feather",
                "Pretenders", "2000 miles",
                "Pink Floyd", "Summer of '69")
```

```{r, results=T}
songs
```

**Exercise**: Can you filter this data set so you keep only the songs that contain a number?

```{r filtersongs, exercise=TRUE, exercise.setup='songs', eval=F}
numbered_songs = filter(songs, ___)
numbered_songs
```
```{r filtersongs-solution}
numbered_songs = filter(songs, str_detect(title, '\\d'))
numbered_songs
```
```{r filtersongs-code-check}
grade_code()
```

### Quantifiers: Finding multiples

The example above contained a pattern looking for a single digit. 
Sometimes, however, we want to match multiple digits. 
For example, 4 consecutive digits could specify a year,
and 5 digits could be an (American) zip code, like the famous 90210 for Beverly hills. 

At its simplest, like 'aa' would match two a's, the pattern '\\d\\d' matches two digits.
We could combine this with a word boundary (`\\b`) as discussed above to only match exactly two digits:

```{r digits, exercise=T, exercise.setup='songs'}
filter(songs, str_detect(title, '\\b\\d\\d\\b'))
```

Apart from repeating the `\\d` (or any other character or pattern), you can also add a **quantifier**.
A quantifier specifies how often the thing before it should be repeated. 
You specify this with curly braces and a number, for example `\\d{4}` matches four digits.
You can also specify a range, so `\\d{2,4}` matches 2 to four digits,
and `\\d{4,}` matches 4 digits or more. 

Because it is so common to look for one or more of something (i.e. `\\d{1,}`), this can be abbreviated to a simple `\\d+`
You can also make something optional, that is: match zero or one of them, by using a question mark as an abbreviation for `{0,1}`. 

```{r quantifiers, exercise=T, results='asis', exercise.setup='strview'}
films = c("12 years a slave", "2001: A space oddisey", "Se7en", "1492: Conquest of Paradise", "10000 Years later")
str_view(films, '\\d\\d')
str_view(films, '\\d{4}')
str_view(films, '\\d+')
```

(Note that the first pattern `\\d\\d` highlights four numbers in e.g. 2001, but these are really two separate matches: it first matches `20`, and then also matches `01`. 

You can also make something optional, that is: match zero or one of them, by using a question mark as an abbreviation for `{0,1}`. 
So, `\\d+:` matches one or more digits followed by a colon, while `\\d+:?` matches one or more digits, optionally followed by a colon:

```{r optional, exercise=T, results='asis', exercise.setup='strview'}
films = c("12 years a slave", "2001: A space oddisey", "Se7en", "1492: Conquest of Paradise", "10000 Years later")
str_view(films, '\\d+:')
str_view(films, '\\d+:?')
```

### Looking for letters

Besides looking for numbers, sometimes we want to look for letters as part of a pattern.
For example, we could look for hashtags as a hash-character followed by one or more letters.

We can use the special symbol `\\b` to find so called '**w**ord characters'. 
Interestingly, this includes numbers and the underscore sign (`_`) as well as letters:

So, we can use the pattern `#\\w+` to find hashtags:
a hash sign followed by one or more word characters.

```{r emails, exercise=TRUE}
tweets = tibble(tweet=c("I love #hashtags #rad", "@vanatteveldt is inactive", "Don't mail me at noreply@example.com #wontwork"))
filter(tweets, str_detect(tweet, '#\\w+'))
```
```{r emails-solution}
tweets = tibble(tweet=c("I love #hashtags #rad", "@vanatteveldt is inactive", "Don't mail me at noreply@example.com #wontwork"))
filter(tweets, str_detect(tweet, '\\w+@\\w+.\\w+'))
```
```{r emails-code-check}
grade_code()
```


**Exercise**: Can you change to pattern above to match (simple) email addresses,
defined here as one or more letters, followed by an at-sign (@), followed by more letters, a period, and more letters? 

Note that there are many ways to solve this, so don't worry if your solution works but it's not the one R was looking for. 

### Looking for symbols

As you have seen, some symbols have a special meaning within regular expressions (patterns):
For example, `+` does not look for a literal plus symbol in the text, rather it means that the preceding character may be repeated. 
Similarly, we've seen that `{}` has a special meaning as a quantifier.
In fact, many non-alphanumeric characters have a special meaning, including periods (`.`), dollar signs (`$`), question marks (`?`), and parentheses (`(` and `)`). 
Note that you don't need to learn all of these now, but if you want there is an overview of symbols at the end of this tutorial if you're curious.

Of course, we sometimes need to look for actual parentheses or question marks. This can be achieved by *escaping* the symbol with a double backslash. 
So, while `.` has a special meaning (spoiler: it matches everything), `\\.` matches only actual periods, and the same for `\\$`, `\\?` and so on. 

### A note on Backslashes and escaping

A small note on the use of backslashes `\`: 
these are said to *escape* the next character, which means that they lose their special meaning.
So, `.` has a special meaning (any character), but `\\.` is "escaped" and returns to just meaning a literal period.

If you 'escape' a regular character such as 'w', the reverse happens: `w` has its literal meaning, but `\\w` has a special meaning (in this case: **w**ord characters). 

In regular expressions, **all** regular alphanumeric characters (a, b, c) are literal matches, 
and some can be made special by escaping them (such as `\\w` and `\\s`).
Similarly, **some** non-alphanumeric characters (such as `.` or `[`) have a special meaning,
and **all** non-alphanumeric characters can be escaped to represent its literal match, so 
`\\.` matches a period, and `\\[` matches an opening square bracket.

Finally, you **need to use double backslashes** every time because otherwise R first processes the text,
and also uses backslashes to escape. So, `\\w` is processed to read `\w`, which is then used in the regular expression.
This also means that, to match a literal backslash, you'd have to use `\\\\`, which is escaped by R to `\\`, which is the regular expression for a literal backslash.


## Extracting patterns

Besides searching for (or filtering on) patterns, we often want to clean up text in various ways.
Suppose we have a data set with open survey responses where we asked people for their email address:

```{r setupt, echo=F}
addresses <- tribble(~id, ~text,
             1, "My address is wouter@example.com",
             2, "I don't want to give my address",
             3, "Don't mail me, just DM at @vanatteveldt",
             4, "dontreply@vu.nl")
```
```{r echo=F}
library(tidyverse)
addresses <- tribble(~id, ~text,
             1, "My address is wouter@example.com",
             2, "I don't want to give my address",
             3, "Don't mail me, just DM at @vanatteveldt",
             4, "dontreply@vu.nl")
```
```{r, results=T}
addresses
```

### Using str_extract 

Besides replacing patterns, it can also be useful to extract elements from a string, for example 
we can extract all hashtags or emails using the (oversimplified) patterns we used earlier

```{r extract0, exercise=TRUE, exercise.setup="setupt"}
addresses |> mutate(email = str_extract(text, "\\w+@\\w+\\.\\w+"))
```

(Note that this only extracts the first occurrence of each pattern. 
Extracting multiple occurrences is more complicated as the results wouldn't really fit in a data frame.
For this, see the 'advanced usage' section below)

### Exercise: Extracting zip codes

As an exercise, can you extract Dutch zip (postal) codes from the data frame below?
Modify the example code (which extracts the first number) to match only zip codes.

Note: A Dutch zip code is four digits, followed by an optional space, followed by two letters.
So, "1234 AB" or "6543zz" would be valid zip codes. 


```{r extract, exercise=TRUE, exercise.setup="strview"}
library(tidyverse)
t <- tibble(text=c("On Singel 445 my zip code was 1012 AB", "9876aa is also a zip code", "There are 9999 air balloons"))
t <- mutate(t, zip=str_extract(text, "\\d+"))
t
```
```{r extract-solution}
library(tidyverse)
t <- tibble(text=c("On Singel 445 my zip code was 1012 AB", "9876aa is also a zip code", "There are 9999 air balloons"))
t <- mutate(t, zip=str_extract(text, "\\b\\d{4} ?\\p{L}{2}\\b"))
t
```
```{r extract-hint-1}
# To match digits, use \\d. To match letters, use \\p{L}
```
```{r extract-hint-2}
# To specify 4 digits, use \\d{4}, and similarly for the letters
```
```{r extract-hint-3}
# To allow for there to be a space or not, use ' ?' (a space followed by a question mark)
```
```{r extract-hint-4}
# Put word bounaries (\\b) around the pattern to make sure it doesn't match the 'ai' in 'air'
```
```{r extract-code-check}
grade_code()
```


This exercise is more challenging than it appears. To create the pattern, just start from the left, 
and convert each element ("four numbers", "an optional space", etc) into the corresponding regular expression syntax.

In the interactive version, you can use the 'hint' button to get hints.

Also note that there are many solutions that are all equally good. For example, `\\d{4}` matches four digits, but so does `[0-9]{4}` or `\\d\\d\\d\\d` -- all of them are perfectly fine. So, if your code works but doesn't match the 'official' solution, don't worry about it and be proud of yourself!


## Advanced usage: Extracting multiple values

So far, all examples in this tutorial produced single values from each string,
e.g. containing whether it found a pattern, the result of a replacement, or a single extracted value.
This made it relatively easy to work with using our known tidyverse functions such as `filter` and `mutate`
(if anything that uses regular expressions can be called easy...)

### List columns

However, in some cases you want to extract multiple values from a string,
or split a string into multiple values. 
Since this places multiple values in a single column, R creates a *list column*
for the result.
For example, let's use `str_extract_all` to extract all the hash tags from the earlier example:


```{r, paged.print=FALSE}
library(tidyverse)
txt = c("Hi, I'm Bob", "my email address  is  Bob@example.com", "A #hashtag for the #millenials")
t = tibble(id=1:3, text=txt)
mutate(t, tags=str_extract_all(text, "#\\w+"))
```

As you can see the resulting column (tags) has a `<list>` type, with the first two rows having zero entries,
and the third having two entries. 

Now, if we want to continue working with these tags we need to first turn them into a regular column.
The best way to deal with this in the context of a data frame is to use `unnest_longer` to turn the list into a long format.

As you can see below, `unnest_longer` duplicates the rows with multiple values, 
similar to how an inner join copies values if either data frame has more rows per case. 

```{r unnest, exercise=TRUE} 
library(tidyverse)
txt = c("Hi, I'm Bob", "my email address  is  Bob@example.com", "A #hashtag for the #millenials")
t = tibble(id=1:3, text=txt)
mutate(t, tags=str_extract_all(text, "#\\w+")) |>
  unnest_longer(tags, keep_empty = TRUE)
```

What happens if you remove the `keep_empty` option?

### Splitting text

Besides extracting multipe values, it can be very useful to split a text column into multiple values. 
For example, a  column could contains multiple data points separated with a comma. 
Suppose we have this data:

```{r getd, remove_for_md=TRUE}
d = tibble(person=c("Liam Jones", "Olivia Smith"), books=c("The great Gatsby, To kill a Mockingbird", "Pride and Prejudice, 1984, Moby Dick"))
d
```
```{r}
d = tibble(person=c("Liam Jones", "Olivia Smith"), books=c("The great Gatsby, To kill a Mockingbird", "Pride and Prejudice, 1984, Moby Dick"))
d
```

If we want to split a column, in this case books, there are two good options: `str_split` and `separate`.

### Using str_split

First, if there is variable number of data points such as the list of books in the data set above, you can use str_split, which takes a regular expression argument to split the column:

```{r, paged.print=F}
mutate(d, books = str_split(books, pattern=","))
```

Just like above, this produces a column of type 'list' which contains multiple values per row.

**Exercise**: Can you normalize the output using `unnest_longer`?
As an added challenge, add a `mutate` call to call the `trimws` function on the resulting column.
This function **strip**s the **w**hite **s**pace from a text.

```{r strsplit, exercise=TRUE, exercise.setup="getd", eval=FALSE}
mutate(d, books = str_split(books, pattern=",")) |>
  unnest_longer(____) |>
  mutate(___)
```
```{r strsplit-solution}
mutate(d, books = str_split(books, pattern=",")) |>
  unnest_longer(books) |>
  mutate(books=trimws(books))
```
```{r strsplit-code-check}
grade_code()
```

### Special case: `separate` for a known amount of columns

As a special case, the `separate` command can be used to split a column into multiple columns,
especially when it always contains the same amount of values. 

For example, the code below uses `separate` to separate the person column into seperate columns for first and last name:

```{r}
d |> separate(person, into=c("firstname", "lastname"), sep=" ")
```

As said, this is mostly useful if a column always contains a fixed number of data points that each have a distinct meaning, e.g. first and last name or city and state. 


## A note on Unicode, UTF-8 and Encoding

::: Info :::::
This section is only needed if you are encountering encoding issues,
especially when dealing with non-Western text. 

You can safely skip this section,
and come back to it if you're having issues with non-latin characters or diacritics.
:::


Finally, a short note about unicode and character encodings.
As with regular expressions, a full explanation of this topic is (well) beyond the scope of this tutorial.
See this [guide on unicode in R](https://kevinushey.github.io/blog/2018/02/21/string-encoding-and-r/)
and the classic [What Every Programmer .. Needs To Know About Encodings ..](http://kunststube.net/encoding/) for some very useful information if you need to know more. 

### Background

A fairly short version of the story is as follows: when computers were mostly dealing with English text, life was easy, as there are not a lot of different letters and they could easily assign each letter and some punctuation marks to a number below 128, so it could be stored as 7 bits. For example, A is number 65. This encoding was called 'ASCII'. 

It turned out, however, that many people needed more than 26 letters, for example to write accented letters. For this reason, the 7 bits were expanded to 8, and many accented latin letters were added. This representation is called latin-1, also known as ISO-8859-1. 

Of course, many languages don't use the latin script, so other 8-bit encodings were invented to deal with Cyrillic, Arabic, and other scripts. Most of these are based on ASCII, meaning that 65 still refers to 'A' in e.g. the Hebrew encoding. However, character 228 could refer to greek Î´, cyrillic Ñ„, or hebrew ×”. Things get even more complex if you consider Chinese, where you can't fit all characters in 256 numbers, so several larger (multi-byte) encodings were used.  

This can cause a lot of confusion if you read a text that was encoding in e.g. greek as if it were encoded in Hebrew. A famous example of this confusion is that Microsoft Exchange used the WingDings font and encoding for rendering symbols in emails, amongst others using character 74 as a smiley. For non-exchange users (who didn't have that font), however, it renders as the ASCII character nr 74: "J". So, if you see an email from a microsoft user with a J where you expected a smiley, now you know `:)`. 

To end this confusion, *unicode* was invented, which assigns a unique number (called a code point) to each letter. A is still 65 (or "\u41" in hexadecimal R notataion), but Î´ is now uniquely "\u03B4", and  Ñ„ is uniquely "\u0444". There are over 1M possible unicode characters, of which about 100 thousand have been currently assigned. This gives enough room for Chinese, old Nordic runes, and even Klingon to be encoded. 

You can directly use these in an R string:

```{r}
"Some Unicode letters: \u41 \u03B4 \u0444"
```

Now, to be able to write all 1M characters to string, one would need almost 24 bits per character, tripling the storage and memory needed to handle most text. So, more efficient encodings were invented that would normally take only 8 or 16 bits per character, but can take more bits if needed. So, while the problem of defining characters is solved, unfortunately you still need to know the actual encoding of a text.
Fortunately, UTF-8 (which uses 1 byte for latin characters, but more for non-western text) is emerging as a de facto standard for most texts. This is a compromise which is most efficient for latin alphabeters, but is still able to unambiguously express all languages.

It is still quite common, however, to encounter text in other encodings, so it can be good to understand what problems you can face and how to deal with them

### Text encoding in R

To show how this works in R, we can use the charToRaw function to see how a character is encoded in R:


```{r, results=T}
charToRaw('A')
```

Note that the output of this function depends on your regional settings (called 'locale'). 
On most computers, this should produce 41 however, as most encodings are based on ASCII. 

For other alphabets it can be more tricky. The Chinese character "è˜­" (unicode "\u862d") on my computer is expressed in UTF-8, where it takes 3 bytes:


### Dealing with encodings

To convert between encodings, you can use the iconv function. For example, to express the Chinese character above in GB2312 (Chinese national standard) encoding:

```{r}
charToRaw(iconv('è˜­', to='GB2312'))
```

The most common way of dealing with encodings is to ignore the problem and hope it goes away. However, outside the English world this is often not an option. Also, due to general unicode ignorance many people will use the wrong encoding, and you will even see things like double-utf8-encoded text. 

The *sane* way to deal with encodings is to make sure that all text stored inside your program is encoded in a standard encoding, presumably UTF-8. This means that whenever you read text from an external source, you need to convert it to UTF-8 if it isn't already in that form. 

This means that when you use `read_csv` (on text data) or `readtext`, you should ideally *always* specify which encoding the text is encoded in:

```{r, eval=F}
readtext::readtext("file.txt", encoding = "utf-8")
read_csv("file.csv", locale=locale(encoding='utf-8'))
```

If you don't know what encoding a text is in, you can try utf-8 and the most common local encodings
(e.g. latin-1 in many western countries), you can inspect the raw bytes, or you can use the guessEncoding function from readr:

```{r, eval=F}
guess_encoding("file.txt")
```

## Overview of regular expression syntax

| Pattern | Explanation |
|---|---|
| owl | Matches the literal text 'owl' |
| regex(owl, ignore_case=T) | Matches case-insensitively, e.g. 'owl', 'Owl', or even 'OWL' |
| \\b | Word boundary, i.e. start or end of word |
| \\bcat\\b | The word 'cat', i.e. not 'cats' or 'locate' |
| \\bdog | A word starting with dog, i.e. 'dog', 'dogs', or 'doggerel' |
| \\d | Any digit, i.e. 1 or 7 |
| \\d\\d | Two digits, i.e. 42 |
| \\d{4} | Exactly four digits, i.e. 1984 |
| \\d{2,4} | Two to four digits, i.e. 69 or 1969 |
| \\d{4,} | At least four digits, i.e. 1984 or 90210 |
| \\d+ | One or more digits |
| \\w | A word character (letter, number, or underscore) |
| \p{L} | A letter

